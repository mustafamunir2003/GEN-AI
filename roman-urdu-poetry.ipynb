{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10667563,"sourceType":"datasetVersion","datasetId":6606712},{"sourceId":10775697,"sourceType":"datasetVersion","datasetId":6685614}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#step 1 load data \n#step 2 chose a archtiture of LSTM (Bidirectional Stacked)\n#step 3 Train \n#step 4 test ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv(\"\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:51:37.868033Z","iopub.status.idle":"2025-02-17T16:51:37.868399Z","shell.execute_reply":"2025-02-17T16:51:37.868214Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=df[['Poetry'][0]]\nx[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:51:37.869296Z","iopub.status.idle":"2025-02-17T16:51:37.869601Z","shell.execute_reply":"2025-02-17T16:51:37.869486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:51:37.870440Z","iopub.status.idle":"2025-02-17T16:51:37.870805Z","shell.execute_reply":"2025-02-17T16:51:37.870607Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Poet'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:51:37.871469Z","iopub.status.idle":"2025-02-17T16:51:37.871807Z","shell.execute_reply":"2025-02-17T16:51:37.871700Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\n\n# Hyperparameters\nEMBEDDING_DIM = 128\nHIDDEN_DIM = 256\nNUM_LAYERS = 2\nBATCH_SIZE = 32\nLEARNING_RATE = 0.001\nEPOCHS = 10\nSEQ_LENGTH = 10\n\n# Load dataset\ndf = pd.read_csv(\"/kaggle/input/roman-poetry/Roman-Urdu-Poetry.csv\")  # Update with the correct file path\npoems = df[\"Poetry\"].tolist()\npoets = df[\"Poet\"].tolist()\n\n# Tokenize and build vocabulary\nwords = set()\nfor poem in poems:\n    words.update(poem.split())\nword_to_idx = {word: i for i, word in enumerate(words)}\nidx_to_word = {i: word for word, i in word_to_idx.items()}\npoet_to_idx = {poet: i for i, poet in enumerate(set(poets))}\n\n# Poetry Dataset\nclass PoetryDataset(Dataset):\n    def __init__(self, poems, poets, word_to_idx, poet_to_idx, seq_length=SEQ_LENGTH):\n        self.poems = poems\n        self.poets = poets\n        self.word_to_idx = word_to_idx\n        self.poet_to_idx = poet_to_idx\n        self.seq_length = seq_length\n        \n        self.data = []\n        for poem, poet in zip(poems, poets):\n            encoded_poem = [word_to_idx[word] for word in poem.split() if word in word_to_idx]\n            poet_idx = poet_to_idx[poet]\n            for i in range(len(encoded_poem) - seq_length):\n                self.data.append((encoded_poem[i:i+seq_length], encoded_poem[i+1:i+seq_length+1], poet_idx))\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        x, y, poet = self.data[idx]\n        return torch.tensor(x), torch.tensor(y), torch.tensor(poet)\n\n# Define LSTM Model\nclass PoetryLSTM(nn.Module):\n    def __init__(self, vocab_size, poet_count, embedding_dim, hidden_dim, num_layers):\n        super(PoetryLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.poet_embedding = nn.Embedding(poet_count, embedding_dim)\n        self.lstm = nn.LSTM(embedding_dim * 2, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n    \n    def forward(self, x, poet):\n        word_embeds = self.embedding(x)  # (batch, seq_len, embed_dim)\n        poet_embeds = self.poet_embedding(poet).unsqueeze(1).repeat(1, x.size(1), 1)  # (batch, seq_len, embed_dim)\n        combined = torch.cat((word_embeds, poet_embeds), dim=2)\n        lstm_out, _ = self.lstm(combined)\n        out = self.fc(lstm_out)\n        return out\n\n# Create Dataset and Dataloader\ndataset = PoetryDataset(poems, poets, word_to_idx, poet_to_idx)\ndataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n\n# Model Initialization\nvocab_size = len(word_to_idx)\npoet_count = len(poet_to_idx)\nmodel = PoetryLSTM(vocab_size, poet_count, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.CrossEntropyLoss()\n\n# Training Function\ndef train_model(model, dataloader, optimizer, criterion, epochs):\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for x, y, poet in dataloader:\n            x, y, poet = x.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), y.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), poet.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n            optimizer.zero_grad()\n            output = model(x, poet)\n            loss = criterion(output.view(-1, vocab_size), y.view(-1))\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / len(dataloader)}\")\n\n# Train Model\ntrain_model(model, dataloader, optimizer, criterion, EPOCHS)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:52:13.498889Z","iopub.execute_input":"2025-02-17T16:52:13.499182Z","iopub.status.idle":"2025-02-17T16:58:03.749604Z","shell.execute_reply.started":"2025-02-17T16:52:13.499161Z","shell.execute_reply":"2025-02-17T16:58:03.748329Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 5.805823723793454\nEpoch 2/10, Loss: 3.703525646347229\nEpoch 3/10, Loss: 2.4856539940271687\nEpoch 4/10, Loss: 1.7547306208065154\nEpoch 5/10, Loss: 1.3084892377118085\nEpoch 6/10, Loss: 1.038669454677401\nEpoch 7/10, Loss: 0.8765590877521288\nEpoch 8/10, Loss: 0.7753250928497017\nEpoch 9/10, Loss: 0.7080525423043242\nEpoch 10/10, Loss: 0.6620812296442949\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def generate_poetry(model, start_words, poet_name, max_length=50):\n    model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    # Convert poet name to index\n    if poet_name not in poet_to_idx:\n        print(\"Poet not found in dataset.\")\n        return \"\"\n    poet_idx = torch.tensor([poet_to_idx[poet_name]], device=device)\n    \n    # Convert start words to indices\n    input_indices = [word_to_idx[word] for word in start_words.split() if word in word_to_idx]\n    if not input_indices:\n        print(\"No valid words found in vocabulary.\")\n        return \"\"\n    \n    input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).unsqueeze(0)  # Add batch dim\n\n    generated_words = start_words.split()\n    \n    for _ in range(max_length):\n        with torch.no_grad():\n            output = model(input_tensor, poet_idx)  # Forward pass\n            predictions = output[:, -1, :]  # Get last token's predictions\n            next_word_idx = torch.argmax(predictions, dim=1).item()  # Choose the most probable word\n            \n            if next_word_idx in idx_to_word:\n                next_word = idx_to_word[next_word_idx]\n                generated_words.append(next_word)\n                input_tensor = torch.cat((input_tensor, torch.tensor([[next_word_idx]], device=device)), dim=1)\n            else:\n                break  # Stop if an invalid word is predicted\n\n    return \" \".join(generated_words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:08.240178Z","iopub.execute_input":"2025-02-17T16:58:08.240666Z","iopub.status.idle":"2025-02-17T16:58:08.247263Z","shell.execute_reply.started":"2025-02-17T16:58:08.240614Z","shell.execute_reply":"2025-02-17T16:58:08.246451Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"poet_name = \"ahmad-faraz\"\nstart_words = \"aaÃ±kh se duur\"\ngenerated_poem = generate_poetry(model, start_words, poet_name)\nprint(\"Generated Poem:\\n\", generated_poem)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:12.640212Z","iopub.execute_input":"2025-02-17T16:58:12.640521Z","iopub.status.idle":"2025-02-17T16:58:12.820109Z","shell.execute_reply.started":"2025-02-17T16:58:12.640498Z","shell.execute_reply":"2025-02-17T16:58:12.819256Z"}},"outputs":[{"name":"stdout","text":"Generated Poem:\n aaÃ±kh se duur bhÄ« hai jaise ham apne hÄ« sÄmne aa.e aaÃ±kh ko be-sabab kyuuÃ± nahÄ«Ã± dete rahzan ho to hÄzir hai matÄ-e-dil-o-jÄÃ± bhÄ« rahbar ho to manzil kÄ pata kyuuÃ± nahÄ«Ã± dete kyÄ biit ga.Ä« ab ke 'farÄz' ahl-e-chaman par yÄrÄn-e-qafas mujh ko sadÄ kyuuÃ± chÄhiye á¸³hudÄ ho jaa.eÃ± ham bhÄ« majbÅ«riyoÃ±\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"poet_name = \"allama-iqbal\"\nstart_words = \"pyaar\"\ngenerated_poem = generate_poetry(model, start_words, poet_name)\nprint(\"Generated Poem:\\n\", generated_poem)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T08:45:20.034898Z","iopub.execute_input":"2025-02-05T08:45:20.035207Z","iopub.status.idle":"2025-02-05T08:45:20.109345Z","shell.execute_reply.started":"2025-02-05T08:45:20.035184Z","shell.execute_reply":"2025-02-05T08:45:20.108705Z"}},"outputs":[{"name":"stdout","text":"Generated Poem:\n pyaar thÄ kisÄ« darmÄÃ±da rah-rau kÄ« sadÄ-e-dardnÄk jis ko ÄvÄz-e-rahÄ«l-e-kÄrvÄÃ± samjhÄ thÄ maiÃ± kah ga.iiÃ± rÄz-e-mohabbat parda-dÄrÄ«-hÄ-e-shauq thÄ« fuÄ¡hÄÃ± vo bhÄ« jise zabt-e-fuÄ¡hÄÃ± samjhÄ thÄ maiÃ± thÄ« kisÄ« darmÄÃ±da rah-rau kÄ« sadÄ-e-dardnÄk jis ko ÄvÄz-e-rahÄ«l-e-kÄrvÄÃ± samjhÄ thÄ maiÃ± kah ga.iiÃ± rÄz-e-mohabbat parda-dÄrÄ«-hÄ-e-shauq thÄ« fuÄ¡hÄÃ± vo bhÄ« jise zabt-e-fuÄ¡hÄÃ± samjhÄ thÄ maiÃ±\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"poet_name = \"faiz-ahmad-faiz\"\nstart_words = \"pyaar\"\ngenerated_poem = generate_poetry(model, start_words, poet_name)\nprint(\"Generated Poem:\\n\", generated_poem)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:16.956630Z","iopub.execute_input":"2025-02-17T16:58:16.956999Z","iopub.status.idle":"2025-02-17T16:58:17.050357Z","shell.execute_reply.started":"2025-02-17T16:58:16.956974Z","shell.execute_reply":"2025-02-17T16:58:17.049704Z"}},"outputs":[{"name":"stdout","text":"Generated Poem:\n pyaar to ghar jÄ.eÃ±ge kis qadar hogÄ yahÄÃ± mehr-o-vafÄ kÄ mÄtam ham tirÄ« yaad se jis roz utar jÄ.eÃ±ge jauharÄ« band kiye jaate haiÃ± bÄzÄr-e-suá¸³han ham kise bechne almÄs-o-guhar jÄ.eÃ±ge nemat-e-zÄ«st kÄ ye qarz chukegÄ kaise laakh ghabrÄ ke ye kahte raheÃ± mar jÄ.eÃ±ge shÄyad apnÄ bhÄ« koÄ« bait hudÄ«-á¸³hvÄÃ± ban\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"torch.save(model.state_dict(), \"poetry_lstm.pth\")\nprint(\"Model saved as poetry_lstm.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:19.372711Z","iopub.execute_input":"2025-02-17T16:58:19.373053Z","iopub.status.idle":"2025-02-17T16:58:19.438717Z","shell.execute_reply.started":"2025-02-17T16:58:19.373027Z","shell.execute_reply":"2025-02-17T16:58:19.437742Z"}},"outputs":[{"name":"stdout","text":"Model saved as poetry_lstm.pth\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import gradio as gr\nimport torch\n\n# Ensure the model is on the correct device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Poetry Generation Function (same as your previous implementation)\ndef generate_poetry(start_words, poet_name, max_length=50):\n    model.eval()\n    \n    # Convert poet name to index\n    if poet_name not in poet_to_idx:\n        return \"Poet not found in dataset.\"\n    poet_idx = torch.tensor([poet_to_idx[poet_name]], device=device)\n    \n    # Convert start words to indices\n    input_indices = [word_to_idx[word] for word in start_words.split() if word in word_to_idx]\n    if not input_indices:\n        return \"No valid words found in vocabulary.\"\n    \n    input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).unsqueeze(0)\n    generated_words = start_words.split()\n    \n    for _ in range(max_length):\n        with torch.no_grad():\n            output = model(input_tensor, poet_idx)\n            predictions = output[:, -1, :]\n            next_word_idx = torch.argmax(predictions, dim=1).item()\n            \n            if next_word_idx in idx_to_word:\n                next_word = idx_to_word[next_word_idx]\n                generated_words.append(next_word)\n                input_tensor = torch.cat((input_tensor, torch.tensor([[next_word_idx]], device=device)), dim=1)\n            else:\n                break\n    \n    return \" \".join(generated_words)\n\n# Define Gradio Interface\ndef poetry_app(start_words, poet_name):\n    return generate_poetry(start_words, poet_name)\n\n# Gradio UI\ntheme = gr.themes.Soft(primary_hue=\"purple\", secondary_hue=\"blue\")\nwith gr.Blocks(theme=theme) as app:\n    gr.Markdown(\"\"\"\n    # âœ¨ Futuristic Roman Urdu Poetry Generator âœ¨\n    **Generate poetry from legendary poets using AI**\n    \"\"\")\n    \n    with gr.Row():\n        poet_name = gr.Dropdown(choices=list(poet_to_idx.keys()), label=\"Select Poet\", interactive=True)\n        start_words = gr.Textbox(label=\"Enter Starting Words\", placeholder=\"aaÃ±kh se duur\")\n    \n    btn_generate = gr.Button(\"Generate Poetry âœï¸\")\n    output = gr.Textbox(label=\"Generated Poetry\", interactive=False, lines=6)\n    \n    btn_generate.click(poetry_app, inputs=[start_words, poet_name], outputs=output)\n    \n    gr.Markdown(\"\"\" \n    ### ğŸŒŒ Features\n    - Choose from famous poets like **Allama Iqbal**, **Ahmad Faraz**, etc.\n    - Start poetry with a custom phrase\n    - Futuristic UI with dark mode aesthetics ğŸŒ™\n    \"\"\")\n\n# Launch App\napp.launch(share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:47.579682Z","iopub.execute_input":"2025-02-17T16:58:47.579997Z","iopub.status.idle":"2025-02-17T16:58:52.843882Z","shell.execute_reply.started":"2025-02-17T16:58:47.579960Z","shell.execute_reply":"2025-02-17T16:58:52.843196Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://fee90f8f85411968c3.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://fee90f8f85411968c3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"!pip install gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T16:58:35.944123Z","iopub.execute_input":"2025-02-17T16:58:35.944420Z","iopub.status.idle":"2025-02-17T16:58:47.578245Z","shell.execute_reply.started":"2025-02-17T16:58:35.944376Z","shell.execute_reply":"2025-02-17T16:58:47.577140Z"}},"outputs":[{"name":"stdout","text":"Collecting gradio\n  Downloading gradio-5.16.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\nCollecting fastapi<1.0,>=0.115.2 (from gradio)\n  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\nCollecting gradio-client==1.7.0 (from gradio)\n  Downloading gradio_client-1.7.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\nRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\nCollecting markupsafe~=2.0 (from gradio)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\nRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\nRequirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.11.0a1)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\nCollecting python-multipart>=0.0.18 (from gradio)\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\nCollecting ruff>=0.9.3 (from gradio)\n  Downloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting starlette<1.0,>=0.40.0 (from gradio)\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\nRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\nCollecting uvicorn>=0.14.0 (from gradio)\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.0->gradio) (2024.9.0)\nRequirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.7.0->gradio) (14.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0,>=1.0->gradio) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.28.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.28.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0,>=1.0->gradio) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.0->gradio) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0,>=1.0->gradio) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading gradio-5.16.0-py3-none-any.whl (62.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.7.0-py3-none-any.whl (321 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading ruff-0.9.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\nDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\nInstalling collected packages: uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\n  Attempting uninstall: markupsafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\nSuccessfully installed fastapi-0.115.8 ffmpy-0.5.0 gradio-5.16.0 gradio-client-1.7.0 markupsafe-2.1.5 python-multipart-0.0.20 ruff-0.9.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.3 tomlkit-0.13.2 uvicorn-0.34.0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}